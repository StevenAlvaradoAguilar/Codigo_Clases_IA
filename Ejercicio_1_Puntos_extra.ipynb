{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Analisis del problema \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4UmARyEJrZn9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importar librerias"
      ],
      "metadata": {
        "id": "Lccuw7ulpSsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu==2.8.0"
      ],
      "metadata": {
        "id": "tyhUv02opdkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d137c6-0a2b-4355-fbee-37a34f864078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu==2.8.0\n",
            "  Downloading tensorflow_gpu-2.8.0-cp310-cp310-manylinux2010_x86_64.whl (497.6 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.6/497.6 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:13\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPZNjCTLrEJP"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  # Use the %tensorflow_version magic if in colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "  \n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, BatchNormalization, Input, Activation, MaxPooling2D, Flatten\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential, model_from_json\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPool2D, MaxPooling2D,SeparableConv2D\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score,ConfusionMatrixDisplay,classification_report\n",
        "\n",
        "import itertools\n",
        "import os\n",
        "import dlib\n",
        "import cv2\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import datetime\n",
        "import plotly.express as px\n",
        "from random import random\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from google.colab.patches import cv2_imshow\n",
        "from numpy import argmax\n",
        "\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental.set_visible_devices([], 'GPU')"
      ],
      "metadata": {
        "id": "d8AmwiyHrwMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "id": "aeEkCpcBpYi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://gitlab.com/ejimenez/beauty/-/raw/main/beauty.zip?inline=false"
      ],
      "metadata": {
        "id": "qi1TA7-SrZvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"beauty.zip?inline=false\""
      ],
      "metadata": {
        "id": "lSMi9txbrzPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga de datos"
      ],
      "metadata": {
        "id": "W1-jKF7Lpk89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento"
      ],
      "metadata": {
        "id": "0yeCYl-VvL_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory = \"/content/beauty/train\"\n",
        "filelist=[]\n",
        "count=0\n",
        "for path, subdirs, files in os.walk(directory):\n",
        "   #print(path, subdirs, files)\n",
        "   for file in files:\n",
        "     img=os.path.join(path, file)\n",
        "     img = cv2.imread(img)\n",
        "     cv2_imshow(img)\n",
        "     if count==10:\n",
        "       break\n",
        "     count=count+1\n",
        "       #if (file.endswith('.wav') or file.endswith('.WAV')):\n",
        "       #    filelist.append(os.path.join(path, file))\n",
        "#number_of_files=len(filelist)\n",
        "#print(number_of_files)"
      ],
      "metadata": {
        "id": "QkLWFdldufD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pruebas"
      ],
      "metadata": {
        "id": "RRpNpFK7vRME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory = \"/content/beauty/test\"\n",
        "filelist=[]\n",
        "count=0\n",
        "for path, subdirs, files in os.walk(directory):\n",
        "   #print(path, subdirs, files)\n",
        "   for file in files:\n",
        "     img=os.path.join(path, file)\n",
        "     img = cv2.imread(img)\n",
        "     cv2_imshow(img)\n",
        "     if count==10:\n",
        "       break\n",
        "     count=count+1\n",
        "       #if (file.endswith('.wav') or file.endswith('.WAV')):\n",
        "       #    filelist.append(os.path.join(path, file))\n",
        "#number_of_files=len(filelist)\n",
        "#print(number_of_files)"
      ],
      "metadata": {
        "id": "V-e-5cenvRME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Categorias"
      ],
      "metadata": {
        "id": "ymLVEMAUvlji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasetDirectory = \"/content/beauty/train\"\n",
        " \n",
        "categories=[]\n",
        "lenCategories=0\n",
        "for folder in os.listdir(datasetDirectory)[:3]:\n",
        "  print(folder)\n",
        "  categories.append(folder)\n",
        "lenCategories= len(categories)"
      ],
      "metadata": {
        "id": "M_V33xtVvoRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size=100\n",
        "\n",
        "training_data=[]\n",
        "\n",
        "def create_training_data():\n",
        "    for category in categories:\n",
        "        path=os.path.join(datasetDirectory, category)\n",
        "        class_num=categories.index(category)\n",
        "        for img in os.listdir(path):\n",
        "            try:                \n",
        "                img_array=cv2.imread(os.path.join(path,img))\n",
        "                new_array=cv2.resize(img_array,(img_size,img_size))\n",
        "                training_data.append([new_array,class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "                pass\n",
        "create_training_data() "
      ],
      "metadata": {
        "id": "wHDH43w-upT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizacion"
      ],
      "metadata": {
        "id": "mQtVCtcYqhYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W_grid = 4\n",
        "L_grid = 4\n",
        "\n",
        "fig, axes = plt.subplots(L_grid, W_grid, figsize = (15, 15))\n",
        "axes = axes.ravel()\n",
        "\n",
        "n_training = len(training_data)\n",
        "\n",
        "for i in np.arange(0, L_grid * W_grid):\n",
        "    index = np.random.randint(0, n_training) # pick a random number\n",
        "    axes[i].imshow(training_data[index][0][:,:,::-1])\n",
        "    axes[i].set_title(training_data[index][1])\n",
        "    axes[i].axis('off')\n",
        "    \n",
        "plt.subplots_adjust(hspace = 0.4)"
      ],
      "metadata": {
        "id": "UGPHNdspqlyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparacion de los datos"
      ],
      "metadata": {
        "id": "9hB9qKzzrRp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=[]\n",
        "y=[]\n",
        "\n",
        "for categories_x, label in training_data:\n",
        "    X.append(categories_x)\n",
        "    y.append(label)\n",
        "X= np.array(X).reshape(len(training_data),-1)"
      ],
      "metadata": {
        "id": "W4nmDapCu5mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X =  X.reshape(len(X),100,100,3)"
      ],
      "metadata": {
        "id": "joe3HqrNCNFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "d-bALyEsCF7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X.shape\n",
        "X = X/255.0\n",
        "y=np.array(y)\n",
        "#y.shape"
      ],
      "metadata": {
        "id": "GNnFnnAau-_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y, return_counts=True)"
      ],
      "metadata": {
        "id": "RCf9V24oDZYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
        "                                                   test_size=0.20,\n",
        "                                                   random_state=0)"
      ],
      "metadata": {
        "id": "5vxHyRx5vele"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = keras.utils.to_categorical(y_train, lenCategories)\n",
        "y_test = keras.utils.to_categorical(y_test, lenCategories)"
      ],
      "metadata": {
        "id": "bmRIa_nv39Rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento del modelo del deep leaning"
      ],
      "metadata": {
        "id": "jGJFOS81tCNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.dataquest.io/blog/learning-curves-machine-learning/\n",
        "# Helper Functions  Learning Curves and Confusion Matrix\n",
        "class MetricsCheckpoint(Callback):\n",
        "    \"\"\"Callback that saves metrics after each epoch\"\"\"\n",
        "    def __init__(self, savepath):\n",
        "        super(MetricsCheckpoint, self).__init__()\n",
        "        self.savepath = savepath\n",
        "        self.history = {}\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        np.save(self.savepath, self.history)\n",
        "\n",
        "def plotKerasLearningCurve():\n",
        "    plt.figure(figsize=(10,5))\n",
        "    metrics = np.load('logs.npy',allow_pickle=True)[()]\n",
        "    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n",
        "    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n",
        "        l = np.array(metrics[k])\n",
        "        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n",
        "        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n",
        "        y = l[x]\n",
        "        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n",
        "        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n",
        "    plt.legend(loc=4)\n",
        "    plt.axis([0, None, None, None]);\n",
        "    plt.grid()\n",
        "    plt.xlabel('Number of epochs')\n",
        "    #plt.show()\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize = (5,5))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    #plt.show()\n",
        "\n",
        "def plot_learning_curve(history):\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.savefig('accuracy_curve.png')\n",
        "    #plt.show()\n",
        "    #plt.clf()\n",
        "    # summarize history for loss\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.savefig('loss_curve.png')\n",
        "    #plt.show()"
      ],
      "metadata": {
        "id": "IGQ0lad8AH-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/\n",
        "\n",
        "\n",
        "\n",
        "The **batch size** is a number of samples processed before the model is updated.\n",
        "\n",
        "The number of **epochs** is the number of complete passes through the training dataset."
      ],
      "metadata": {
        "id": "Kxd9fDQNgDx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def runKerasCNNAugment(a,b,c,d,e):\n",
        "    \"\"\"\n",
        "    Run Keras CNN: https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n",
        "    \"\"\"\n",
        "    chanDim = -1\n",
        "    batch_size = 64\n",
        "    num_classes = e\n",
        "    epochs = 40\n",
        "    img_rows,img_cols=100,100\n",
        "    input_shape = (img_rows, img_cols, 3)\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', \n",
        "                                     input_shape = (100,100,3)))\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3,3), activation = 'relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'))\n",
        "    #model.add(tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))    \n",
        "\n",
        "    #model.add(tf.keras.layers.Conv2D(128, (3,3), activation = 'relu'))\n",
        "    #model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
        "    #model.add(tf.keras.layers.Dropout(0.2))   \n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(1024, activation = 'relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(1024, activation = 'relu'))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(num_classes, activation = 'softmax'))\n",
        "    model.summary()\n",
        "\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "    model.compile(optimizer = opt, loss = 'BinaryCrossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True)  # randomly flip images\n",
        "\n",
        "    t= time.time()\n",
        "    export= './frutas_{}.h5'.format(int(t))\n",
        "    checkpoint_filepath = export\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "    \n",
        "    history = model.fit(datagen.flow(a,b, batch_size=batch_size),\n",
        "                                  steps_per_epoch=len(a) / batch_size,\n",
        "                                  epochs=epochs,\n",
        "                        validation_data = (c, d),callbacks = [MetricsCheckpoint('logs'),model_checkpoint_callback] )\n",
        "    score = model.evaluate(c,d, verbose=0)\n",
        "    print('\\nKeras CNN #1C - accuracy:', score[1],'\\n')\n",
        "    y_pred = model.predict(c)\n",
        "    print('\\n', classification_report(np.where(d > 0)[1], np.argmax(y_pred, axis=1), \n",
        "                                                    target_names=list(categories)), sep='')  \n",
        "    y_pred=np.argmax(y_pred,axis=1)\n",
        "    Y_true =np.argmax(d,axis=1)\n",
        "    plotKerasLearningCurve()\n",
        "    plt.show()  \n",
        "    plot_learning_curve(history)\n",
        "    plt.show()\n",
        "\n",
        "    confusion_mtx = confusion_matrix(Y_true, y_pred) \n",
        "    plot_confusion_matrix(confusion_mtx, classes = list(np.unique(b))) \n",
        "    plt.show()\n",
        "    return model\n",
        " \n",
        "#modelo=runKerasCNNAugment(X_train, y_train, X_test, y_test,len(categories),class_weight2)\n",
        "modelo=runKerasCNNAugment(X_train, y_train , X_test, y_test,len(categories))\n"
      ],
      "metadata": {
        "id": "7mFrx-vr6dWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"on valid data\")\n",
        "pred1=modelo.evaluate(X_test, y_test)\n",
        "print(\"accuaracy\", str(pred1[1]*100))\n",
        "print(\"Total loss\",str(pred1[0]*100))"
      ],
      "metadata": {
        "id": "uX8KNZdPfjjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluacion"
      ],
      "metadata": {
        "id": "_x6ylxeOtHIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_classes = modelo.predict(X_test) \n",
        "predicted_classes=np.argmax(predicted_classes,axis=1)"
      ],
      "metadata": {
        "id": "iQF15TJw-t7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = modelo.evaluate(X_test, y_test)\n",
        "print('Test Accuracy: {}'.format(evaluation[1]))"
      ],
      "metadata": {
        "id": "YRyr1RGV9m1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(y_test, axis=1, out=None)"
      ],
      "metadata": {
        "id": "Be-XG8A9Uy5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cm = confusion_matrix(np.argmax(y_test, axis=1, out=None), predicted_classes)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=categories)\n",
        "\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show() "
      ],
      "metadata": {
        "id": "b7TUkpExCgbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L = 7\n",
        "W = 7\n",
        "fig, axes = plt.subplots(L, W, figsize = (12, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in np.arange(0, L*W):\n",
        "    axes[i].imshow(X_test[i][:,:,::-1])\n",
        "    axes[i].set_title('Prediction = {}\\n True = {}'.format(predicted_classes[i], np.argmax(y_test[i], axis=None, out=None)))\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.subplots_adjust(wspace = 1)   "
      ],
      "metadata": {
        "id": "aTNH8J4r9uP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.layers"
      ],
      "metadata": {
        "id": "3WtekeNDVuGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve weights from the second hidden layer\n",
        "filters, biases = modelo.layers[0].get_weights()\n",
        "# normalize filter values to 0-1 so we can visualize them\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "# plot first few filters\n",
        "n_filters, ix = 6, 1\n",
        "for i in range(n_filters):\n",
        "\t# get the filter\n",
        "\tf = filters[:, :, :, i]\n",
        "\t# plot each channel separately\n",
        "\tfor j in range(3):\n",
        "\t\t# specify subplot and turn of axis\n",
        "\t\tax = plt.subplot(n_filters, 3, ix)\n",
        "\t\tax.set_xticks([])\n",
        "\t\tax.set_yticks([])\n",
        "\t\t# plot filter channel in grayscale\n",
        "\t\tplt.imshow(f[:, :, j], cmap='gray')\n",
        "\t\tix += 1\n",
        "# show the figure\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e8qvqrc0WGLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve weights from the second hidden layer\n",
        "filters, biases = modelo.layers[1].get_weights()\n",
        "# normalize filter values to 0-1 so we can visualize them\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "# plot first few filters\n",
        "n_filters, ix = 6, 1\n",
        "for i in range(n_filters):\n",
        "\t# get the filter\n",
        "\tf = filters[:, :, :, i]\n",
        "\t# plot each channel separately\n",
        "\tfor j in range(3):\n",
        "\t\t# specify subplot and turn of axis\n",
        "\t\tax = plt.subplot(n_filters, 3, ix)\n",
        "\t\tax.set_xticks([])\n",
        "\t\tax.set_yticks([])\n",
        "\t\t# plot filter channel in grayscale\n",
        "\t\tplt.imshow(f[:, :, j], cmap='gray')\n",
        "\t\tix += 1\n",
        "# show the figure\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MzgQ8xR7RkzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve weights from the second hidden layer\n",
        "filters, biases = modelo.layers[4].get_weights()\n",
        "# normalize filter values to 0-1 so we can visualize them\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "# plot first few filters\n",
        "n_filters, ix = 6, 1\n",
        "for i in range(n_filters):\n",
        "\t# get the filter\n",
        "\tf = filters[:, :, :, i]\n",
        "\t# plot each channel separately\n",
        "\tfor j in range(3):\n",
        "\t\t# specify subplot and turn of axis\n",
        "\t\tax = plt.subplot(n_filters, 3, ix)\n",
        "\t\tax.set_xticks([])\n",
        "\t\tax.set_yticks([])\n",
        "\t\t# plot filter channel in grayscale\n",
        "\t\tplt.imshow(f[:, :, j], cmap='gray')\n",
        "\t\tix += 1\n",
        "# show the figure\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7gJkBxDkWQll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Angelina_Jolie_2_June_2014_%28cropped%29.jpg/330px-Angelina_Jolie_2_June_2014_%28cropped%29.jpg"
      ],
      "metadata": {
        "id": "CNTpOb0fwvlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from numpy import expand_dims\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "# redefine model to output right after the first hidden layer\n",
        "model = Model(inputs=modelo.inputs, outputs=modelo.layers[4].output)\n",
        "model.summary()\n",
        "# load the image with the required shape\n",
        "img = load_img('330px-Angelina_Jolie_2_June_2014_(cropped).jpg', target_size=(100, 100,3))\n",
        "# convert the image to an array\n",
        "img = img_to_array(img)\n",
        "# expand dimensions so that it represents a single 'sample'\n",
        "img = expand_dims(img, axis=0)\n",
        "# prepare the image (e.g. scale pixel values for the vgg)\n",
        "img = preprocess_input(img)\n",
        "# get feature map for first hidden layer\n",
        "feature_maps = model.predict(img)\n",
        "# plot all 64 maps in an 8x8 squares\n",
        "square = 8\n",
        "print(feature_maps.shape)\n",
        "\n",
        "ix = 1\n",
        "for _ in range(square):\n",
        "\tfor _ in range(square):\n",
        "\t\t# specify subplot and turn of axis\n",
        "\t\tax = plt.subplot(square, square, ix,)\n",
        "\t\tax.set_xticks([])\n",
        "\t\tax.set_yticks([])\n",
        "\t\t# plot filter channel in grayscale\n",
        "\t\tplt.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\n",
        "\t\tix += 1\n",
        "# show the figure\n",
        "plt.show()\n",
        "plt.subplots_adjust(wspace = 1)  "
      ],
      "metadata": {
        "id": "VMa4yzR1WZPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
        "activations = activation_model.predict(X_train[10].reshape(1,100,100,3))\n",
        "\n",
        "\n",
        "print(X_train[10].shape)\n",
        "\n",
        "plt.imshow(X_train[10][:,:,0]);\n",
        "\n",
        "\n",
        "def display_activation(activations, col_size, row_size, act_index): \n",
        "    activation = activations[act_index]\n",
        "    activation_index=0\n",
        "    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*2.5,col_size*1.5))\n",
        "    for row in range(0,row_size):\n",
        "        for col in range(0,col_size):\n",
        "            ax[row][col].imshow(activation[0, :, :, activation_index], cmap='gray')\n",
        "            activation_index += 1\n",
        "        \n",
        "\n"
      ],
      "metadata": {
        "id": "TQ0_XeySbXe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.codeastar.com/visualize-convolutional-neural-network/\n",
        "display_activation(activations, 4, 4, 3)"
      ],
      "metadata": {
        "id": "3U42kZtVcOKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusiones"
      ],
      "metadata": {
        "id": "ZbpDubLPtI5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los resultados de la evaluación en los datos de validación muestran una precisión (accuracy) del 95.63% y una pérdida (loss) total del 12.78%.\n",
        "\n",
        "Esto significa que el modelo alcanzó una precisión del 95.63%, lo cual indica que es capaz de clasificar correctamente la mayoría de las muestras de los datos de validación. Sin embargo, se observa una pérdida relativamente alta del 12.78%, lo que indica que el modelo todavía comete algunos errores al predecir las etiquetas correctas.\n",
        "\n",
        "En general, se puede concluir que el modelo tiene un desempeño bastante bueno en los datos de validación, pero aún puede mejorarse para reducir la pérdida y aumentar la precisión."
      ],
      "metadata": {
        "id": "0o2UB3aS1kRI"
      }
    }
  ]
}